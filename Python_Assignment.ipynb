{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRa6FjjDUhV9",
        "colab_type": "text"
      },
      "source": [
        "We have use the `nltk.corpus` `movie_reviews` to get the data set\n",
        "\n",
        "\n",
        "\n",
        "> From this we have seperate out the positive reviews data in `pos_reviews` and \n",
        "negative reviews data in `neg_reviews`\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmXuwDA4szMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import movie_reviews \n",
        "import nltk\n",
        "\n",
        "nltk.download('movie_reviews') # downloading the data set\n",
        "\n",
        "pos_reviews = [] \n",
        "for fileid in movie_reviews.fileids('pos'):\n",
        "    words = movie_reviews.words(fileid)\n",
        "    pos_reviews.append(words)\n",
        " \n",
        "neg_reviews = []\n",
        "for fileid in movie_reviews.fileids('neg'):\n",
        "    words = movie_reviews.words(fileid)\n",
        "    neg_reviews.append(words)\n",
        " \n",
        "# print first positive review item from the pos_reviews list\n",
        "print (pos_reviews[0])\n",
        "'''\n",
        "Output:\n",
        " \n",
        "['films', 'adapted', 'from', 'comic', 'books', ...]\n",
        "'''\n",
        " \n",
        "# print first negative review item from the neg_reviews list\n",
        "print (neg_reviews[0])\n",
        "'''\n",
        "Output:\n",
        " \n",
        "['plot', ':', 'two', 'teen', 'couples', 'go', ...]\n",
        "'''\n",
        " \n",
        "# print first 20 items of the first item of positive review\n",
        "print (pos_reviews[0][:20])\n",
        "'''\n",
        "Output:\n",
        " \n",
        "['films', 'adapted', 'from', 'comic', 'books', 'have', 'had', 'plenty', 'of', 'success', ',', 'whether', 'they', \"'\", 're', 'about', 'superheroes', '(', 'batman', ',']\n",
        "'''\n",
        " \n",
        "# print first 20 items of the first item of negative review\n",
        "print (neg_reviews[0][:20])\n",
        "'''\n",
        "Output:\n",
        " \n",
        "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.', 'they', 'get', 'into', 'an']\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqpk-vcTUeDh",
        "colab_type": "text"
      },
      "source": [
        "Firstly, We will do data cleaning by removing stop words and punctuations.\n",
        "\n",
        "> **Stop words** are those frequently words which do not carry any significant meaning in text analysis. For example, I, me, my, the, a, and, is, are, he, she, we, etc.\n",
        "**Punctuation marks** like comma, fullstop. inverted comma, etc. occur highly in any text data.\n",
        "\n",
        "# Create Feature Set\n",
        "\n",
        "<ul>\n",
        "  <li>Now, we write a function that will be used to create feature set. The feature set is used to train the classifier.</li>\n",
        "  <li>We use the bag-of-words feature and tag each review with its respective category as positive or negative.</li>\n",
        "</ul>\n",
        "\n",
        "\n",
        "```\n",
        "Read bag of words feature in Readme.md\n",
        "```\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB8PRQG_wO8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords \n",
        "import string \n",
        "nltk.download('stopwords')\n",
        "stopwords_english = stopwords.words('english')\n",
        " \n",
        "# feature extractor function\n",
        "def bag_of_words(words):\n",
        "    words_clean = []\n",
        " \n",
        "    for word in words:\n",
        "        word = word.lower()\n",
        "        if word not in stopwords_english and word not in string.punctuation:\n",
        "            words_clean.append(word)\n",
        "    \n",
        "    words_dictionary = dict([word, True] for word in words_clean)\n",
        "    \n",
        "    return words_dictionary\n",
        " \n",
        "# using dict will remove duplicate words from the words list\n",
        "# note the output: stopword 'the' is also removed\n",
        "print (bag_of_words(['the', 'the', 'good', 'bad', 'the', 'good']))\n",
        "'''\n",
        "Output:\n",
        " \n",
        "{'good': True, 'bad': True}\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNMou6CMeU65",
        "colab_type": "text"
      },
      "source": [
        "Here, we made the `pos_reviews_set` and `neg_reviews_set` which is different from the above defined `pos_reviews` and `neg_reviews`.\n",
        "The `pos_reviews_set` and `neg_reviews_set` content the words feature list\n",
        "\n",
        "which is use to create **train** and **test set**.\n",
        "\n",
        "> **Train Set** : is used to train the classifier.\n",
        "\n",
        "> **Test Set** : is used to test the classifier to check how accurately it classifies the given text. \n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXkzrzobwqiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# positive reviews feature set\n",
        "pos_reviews_set = []\n",
        "for words in pos_reviews:\n",
        "    pos_reviews_set.append((bag_of_words(words), 'pos'))\n",
        " \n",
        "# negative reviews feature set\n",
        "neg_reviews_set = []\n",
        "for words in neg_reviews:\n",
        "    neg_reviews_set.append((bag_of_words(words), 'neg'))\n",
        " \n",
        "# print first positive review item from the pos_reviews list\n",
        "print (pos_reviews_set[0])\n",
        "'''\n",
        "Output:\n",
        " \n",
        "({'childs': True, 'steve': True, 'surgical': True, 'go': True, 'certainly': True, 'watchmen': True, 'song': True, 'simpsons': True, 'novel': True, ........................................................................\n",
        "........................................................ 'menace': True, 'starting': True, 'original': True}, 'pos')\n",
        "'''\n",
        "\n",
        "# print first negative review item from the neg_reviews list\n",
        "print (neg_reviews_set[0])\n",
        "'''\n",
        "Output:\n",
        " \n",
        "({'concept': True, 'skip': True, 'insight': True, 'playing': True, 'executed': True, 'go': True, 'still': True, 'find': True, 'seemed': True, .............................................................................................\n",
        "................................................. 'entertaining': True, 'years': True, 'away': True, 'came': True}, 'neg')\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uExKbcVziOx0",
        "colab_type": "text"
      },
      "source": [
        "<h3>Here we have just created the train set and test set with `train_set` and `test_set` arrays respectively.</h3>\n",
        "\n",
        "# Create Train and Test Set\n",
        "\n",
        "\n",
        "> There are 1000 positive reviews set and 1000 negative reviews set. We take 20% (i.e. 200) of positive reviews and 20% (i.e. 200) of negative reviews as a test set. The remaining negative and positive reviews will be taken as a training set.\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij_cm7zNwvwG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (len(pos_reviews_set), len(neg_reviews_set)) # Output: (1000, 1000)\n",
        " \n",
        "# radomize pos_reviews_set and neg_reviews_set\n",
        "# doing so will output different accuracy result everytime we run the program\n",
        "from random import shuffle \n",
        "shuffle(pos_reviews_set)\n",
        "shuffle(neg_reviews_set)\n",
        " \n",
        "test_set = pos_reviews_set[:200] + neg_reviews_set[:200]\n",
        "train_set = pos_reviews_set[200:] + neg_reviews_set[200:]\n",
        "X_count_vect =  pos_reviews_set + neg_reviews_set\n",
        "print(len(test_set),  len(train_set)) # Output: (400, 1600)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEbJh3bPjqsL",
        "colab_type": "text"
      },
      "source": [
        "#Testing the trained Classifier\n",
        "\n",
        "Letâ€™s see the accuracy percentage of the trained classifier. The accuracy value changes each time you run the program because of the names array being shuffled above.\n",
        "\n",
        "---\n",
        "\n",
        "#Training Classifier and Calculating Accuracy\n",
        "\n",
        "We train Naive Bayes Classifier using the training set and calculate the classification accuracy of the trained classifier using the test set.\n",
        "\n more on Naive Bayes Classifier:\n",
        "> https://en.wikipedia.org/wiki/Naive_Bayes_classifier\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eZah_Mlw72a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk import classify\n",
        "from nltk import NaiveBayesClassifier\n",
        " \n",
        "classifier = NaiveBayesClassifier.train(train_set)\n",
        " \n",
        "accuracy = classify.accuracy(classifier, test_set)\n",
        "print(accuracy) # Output: 0.7325\n",
        " \n",
        "print (classifier.show_most_informative_features(10))\n",
        "'''\n",
        "Output:\n",
        " \n",
        "Most Informative Features\n",
        "            breathtaking = True              pos : neg    =     20.3 : 1.0\n",
        "                dazzling = True              pos : neg    =     12.3 : 1.0\n",
        "               ludicrous = True              neg : pos    =     12.2 : 1.0\n",
        "             outstanding = True              pos : neg    =     10.6 : 1.0\n",
        "                 insipid = True              neg : pos    =     10.3 : 1.0\n",
        "               stretched = True              neg : pos    =     10.3 : 1.0\n",
        "               stupidity = True              neg : pos    =     10.2 : 1.0\n",
        "                  annual = True              pos : neg    =      9.7 : 1.0\n",
        "                headache = True              neg : pos    =      9.7 : 1.0\n",
        "                  avoids = True              pos : neg    =      9.7 : 1.0\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMhO277mmCBC",
        "colab_type": "text"
      },
      "source": [
        "#Observations:\n",
        "Letâ€™s see the most informative features among the entire features in the feature set.\n",
        "\n",
        "The result shows that the word outstanding is used in positive reviews 10.6 times more often than it is used in negative reviews the word insipid is used in negative reviews 10.3 times more often than it is used in positive reviews. Similarly, for other letters. These ratios are also called likelihood ratios.\n",
        "\n",
        "Therefore, a review has a high chance to be classified as positive if it contains words like outstanding and breathtaking. Similarly, a review has a high chance of being classified as negative if it contains words like insipid, awful, waste, etc.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgP3o-54mByq",
        "colab_type": "text"
      },
      "source": [
        "#Testing Classifier with Custom Review\n",
        "\n",
        "We provide custom review text and check the classification output of the trained classifier. The classifier correctly predicts both negative and positive reviews provided.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lAUpDWlxCPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt') \n",
        "custom_review = \"Worst movie i have ever seen. It is worst then the corona virus, disasteres.\"\n",
        "custom_review_tokens = word_tokenize(custom_review)\n",
        "custom_review_set = bag_of_words(custom_review_tokens)\n",
        "print (classifier.classify(custom_review_set)) # Output: neg\n",
        "# Negative review correctly classified as negative\n",
        " \n",
        "# probability result\n",
        "prob_result = classifier.prob_classify(custom_review_set)\n",
        "print (prob_result) # Output: <ProbDist with 2 samples>\n",
        "print (prob_result.max()) # Output: neg\n",
        "print (prob_result.prob(\"neg\")) # Output: 0.6721163089262822\n",
        "print (prob_result.prob(\"pos\")) # Output: 0.32788369107371845\n",
        " \n",
        "custom_review = \"Better then Corona, its good to watch movie like this, wonderful.\"\n",
        "custom_review_tokens = word_tokenize(custom_review)\n",
        "custom_review_set = bag_of_words(custom_review_tokens)\n",
        " \n",
        "print (classifier.classify(custom_review_set)) # Output: pos\n",
        "# Positive review correctly classified as positive\n",
        " \n",
        "# probability result\n",
        "prob_result = classifier.prob_classify(custom_review_set)\n",
        "print (prob_result) # Output: <ProbDist with 2 samples>\n",
        "print (prob_result.max()) # Output: pos\n",
        "print (prob_result.prob(\"neg\")) # Output: 0.12709507150838628\n",
        "print (prob_result.prob(\"pos\")) # Output: 0.8729049284916135"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
